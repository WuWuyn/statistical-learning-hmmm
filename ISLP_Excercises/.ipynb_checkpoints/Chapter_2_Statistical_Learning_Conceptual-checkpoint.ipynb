{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b50de8-7555-4f18-9606-7fce758fc6c3",
   "metadata": {},
   "source": [
    "# Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75083d70-8d09-4ae7-8a6b-54002aad484a",
   "metadata": {},
   "source": [
    "## Excercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d4132-e7e4-4ba8-bbb7-e88e0fb2648a",
   "metadata": {},
   "source": [
    "For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\n",
    "\n",
    "(a) The sample size $\\textit{n}$ is extremely large, and the number of predictors $\\textit{p}$ is small\n",
    "\n",
    "(b) The number of predictors $\\textit{p}$ is extremely large, and the number of observations $\\textit{n}$ is small.\n",
    "\n",
    "(c) The relationship between the predictors and response is highly non-linear.\n",
    "\n",
    "(d) The variance of the error terms, i.e. $\\sigma^2 = Var(\\epsilon)$, is extremely high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad46110-6127-433c-b8cf-46404470789b",
   "metadata": {},
   "source": [
    "**Solved:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8aa61c-64d2-4edd-8640-1f6a333e111c",
   "metadata": {},
   "source": [
    "**Review Core Concepts:**\n",
    "- **Flexibility:** Refers to how complex a model the statiscal learning method can fit. High flexibility allows fitting intricate patterns (e.g., non-linear relationshop), while low flexibility imposes stronger constraints (e.g., linearity).\n",
    "- **Inflexible Methods:** They have **low variance** (the fitted model doesn't change much with different training sets) but potentially **high bias** (the model's assumptions might be too simple to capture the true underlying relationship f). (Example: Linear Regression...)\n",
    "- **Flexible Methods:** They have **low bias** (can approximate complex true relationships f) but potentially **high variance** (can fit the noise in the training data, leading to overfitting and poor perfomance on unseen data). (Example: KNN with small K, high-degree polynomial regression...)\n",
    "- **Perfomance:** Typically measured by prediction accuracy on unseen **test data**. This is related to the Test Mean Squared Error (MSE) for regression or Test Error Rate for classification.\n",
    "- **Bias-Variance Trade-off:** TestError $\\approx$ Bias^2 + Variance + Irreducible Error($\\sigma^2$). The goal is to minimize this total error. Increasing flexibility generally decreases bias but increases variance. The optimal method balances this trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be600f44-ba38-4e68-b45c-5fb444812b56",
   "metadata": {},
   "source": [
    "**(a) The sample size $\\textit{n}$ is extremely large, and the number of predictors $\\textit{p}$ is small.**\n",
    "- Expected Performance: A flexible method will likely perform better.\n",
    "- Justification:\n",
    "    - Bias: A flexible method has lower bias and can capture potentially complex underlying relationships between the predictors and the response.\n",
    "    - Variance: The main drawback of flexible methods is high variance (overfitting). However, with an *extremely large sample size (**n**)*, the risk of overfitting decreases significantly. The model can learn complex patterns from the abundant data without being overly influenced by the noise in any small subset of it.\n",
    "    - Trade-off: Since large **n** mitigates the high variance issue associated with flexible models, we can benefit from their low bias to achieve better overall performance, especially if the true relationship **f** has some non-linearity. The small number of predictors **p** also helps, avoiding the \"curse of dimensionality\" which can make even large datasets seem sparse and hamper flexible methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f036954-19a5-4428-bf33-a293fe9bcf49",
   "metadata": {},
   "source": [
    "**(b) The number of predictors *p* is extremely large, and the number of observations *n* is small.**\n",
    "- Expected Performance: An inflexible method will likely perform better.\n",
    "- Justification:\n",
    "    - Bias: An inflexible method might have higher bias if the true relationship f is complex\n",
    "    - Variance: When p >> n (many predictors, few observations), flexible methods have too much freedom. They can find spurious patterns in the training data and fit the noise almost perfectly, leading to extreme overfitting and very high variance. Their performance on unseen test data will be very poor\n",
    "    - Trade-off: In the p >> n scenario, controlling variance is paramount. Inflexible methods, by imposing strong structural assumptions (like linearity), significantly restrict the model complexity and thus keep the variance low. Even if they introduce some bias, the massive reduction in variance compared to a flexible model typically leads to better test performance. Flexible methods suffer greatly from the curse of dimensionality here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d53103-4581-4fad-b849-238ecd62a2d7",
   "metadata": {},
   "source": [
    "## Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecabab-6ea5-45bf-babf-c548ac548201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d24136-5342-4611-966a-1e5ce1d82338",
   "metadata": {},
   "source": [
    "## Excercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9e311-48d8-43a5-b6d1-4c270b9cb02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb87e10-4638-418b-ae30-7cbad9c2bba4",
   "metadata": {},
   "source": [
    "## Excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431a9fe-939e-4bf7-8033-a8d4be986cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b9190c-0e87-4dcf-8b8f-c1695de9035a",
   "metadata": {},
   "source": [
    "## Excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e0f64-9a95-4df0-a792-0f58a11f4079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924039cf-490f-4a16-94de-f928433d7c88",
   "metadata": {},
   "source": [
    "## Excercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01f0c0-9757-4277-a801-15b86e6a135f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5660363b-3e6e-4bd3-9d77-fd7dc9079a61",
   "metadata": {},
   "source": [
    "## Excercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d79c7e-1070-4468-bd20-268d8882b465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29a84d3-b84e-4a60-8252-8d65af49b2c8",
   "metadata": {},
   "source": [
    "# Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff877a-9957-4f99-8845-2547a159e2be",
   "metadata": {},
   "source": [
    "## Excercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50eb48-a5ce-427c-bda3-112e75f6394a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "305c5461-77fd-4ae1-a949-5a5d082632ab",
   "metadata": {},
   "source": [
    "## Excercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86256e42-89a4-4454-b193-cc33ab4ecee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8425c8a6-cddb-4df6-b990-8fc831b7b3ce",
   "metadata": {},
   "source": [
    "## Excercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe21f07-3c85-45b6-ac7f-425db26ec164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
